{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33914335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import query\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import yaml\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525ddb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=config.api_key,\n",
    "    base_url=config.base_url,\n",
    ")\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        completion = client.embeddings.create(\n",
    "            model=config.embed_model,\n",
    "            input=text,\n",
    "            dimensions=1024,\n",
    "            encoding_format=\"float\"\n",
    "        )\n",
    "        return completion.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting text embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e6b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the theme of the lesson?\"\n",
    "query_embed = get_text_embedding(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e693d8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID List: ['video_lecture_0', 'video_lecture_1', 'video_lecture_2', 'video_lecture_3', 'video_lecture_4', 'video_lecture_5', 'video_lecture_6', 'video_lecture_7']\n",
      "Nearest neighbor indices of the query vector:\n",
      " [[20  3 12]]\n",
      "Nearest neighbor distances of the query vector:\n",
      " [[0.9111115  0.92139447 0.9285326 ]]\n",
      "subtitle_end_time: '00:00:28.550'\n",
      "subtitle_start_time: '00:00:26.480'\n",
      "subtitle_text: 'align:start position:0%\n",
      "\n",
      "  you uh to tell me what would actually be\n",
      "\n",
      "  the<00:00:26.720><c> first</c><00:00:27.240><c> object</c><00:00:27.640><c> that</c><00:00:27.720><c>\n",
      "  you</c><00:00:27.920><c> pay</c><00:00:28.119><c> attention</c>'\n",
      "video_id: video_lecture_0\n",
      "\n",
      "subtitle_end_time: '00:00:04.880'\n",
      "subtitle_start_time: '00:00:04.870'\n",
      "subtitle_text: 'align:start position:0%\n",
      "\n",
      "  discussion about convolutional new'\n",
      "video_id: video_lecture_0\n",
      "\n",
      "subtitle_end_time: '00:00:17.510'\n",
      "subtitle_start_time: '00:00:15.879'\n",
      "subtitle_text: 'align:start position:0%\n",
      "\n",
      "  uh to um address problems that we are\n",
      "\n",
      "  facing<00:00:16.240><c> in</c><00:00:16.440><c> computer</c><00:00:16.840><c> vision</c><00:00:17.160><c>\n",
      "  I</c><00:00:17.240><c> want</c><00:00:17.400><c> to</c>'\n",
      "video_id: video_lecture_0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_ids = query.get_all_video_ids()\n",
    "print(\"Video ID List:\", video_ids)\n",
    "\n",
    "query_vector = query_embed\n",
    "distances, indices, frames = query.search_similar_frames(query_vector, num_results=3)\n",
    "\n",
    "print(\"Nearest neighbor indices of the query vector:\\n\", indices)\n",
    "print(\"Nearest neighbor distances of the query vector:\\n\", distances)\n",
    "\n",
    "for i in indices[0]:\n",
    "    data = {\n",
    "        'video_id': frames[i]['video_id'],\n",
    "        'subtitle_start_time': frames[i]['subtitle_start_time'],\n",
    "        'subtitle_end_time': frames[i]['subtitle_end_time'],\n",
    "        'subtitle_text': frames[i]['subtitle_text']\n",
    "    }\n",
    "    yaml_str = yaml.dump(data, default_flow_style=False, allow_unicode=True)\n",
    "    print(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad04206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " \n",
      "Use the context information provided below to answer the final question. If the context information is insufficient to answer the question, please indicate that you cannot find relevant information.\n",
      "\n",
      "Context information:\n",
      "subtitle_end_time: '00:00:28.550'\n",
      "subtitle_start_time: '00:00:26.480'\n",
      "subtitle_text: 'align:start position:0%\n",
      "\n",
      "  you uh to tell me what would actually be\n",
      "\n",
      "  the<00:00:26.720><c> first</c><00:00:27.240><c> object</c><00:00:27.640><c> that</c><00:00:27.720><c>\n",
      "  you</c><00:00:27.920><c> pay</c><00:00:28.119><c> attention</c>'\n",
      "video_id: video_lecture_0\n",
      "\n",
      "subtitle_end_time: '00:00:04.880'\n",
      "subtitle_start_time: '00:00:04.870'\n",
      "subtitle_text: 'align:start position:0%\n",
      "\n",
      "  discussion about convolutional new'\n",
      "video_id: video_lecture_0\n",
      "\n",
      "subtitle_end_time: '00:00:17.510'\n",
      "subtitle_start_time: '00:00:15.879'\n",
      "subtitle_text: 'align:start position:0%\n",
      "\n",
      "  uh to um address problems that we are\n",
      "\n",
      "  facing<00:00:16.240><c> in</c><00:00:16.440><c> computer</c><00:00:16.840><c> vision</c><00:00:17.160><c>\n",
      "  I</c><00:00:17.240><c> want</c><00:00:17.400><c> to</c>'\n",
      "video_id: video_lecture_0\n",
      "\n",
      "\n",
      "\n",
      "Question:\n",
      "What is the theme of the lesson?\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Use the context information provided below to answer the final question. If the context information is insufficient to answer the question, please indicate that you cannot find relevant information.\n",
    "\n",
    "Context information:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "'''\n",
    "context = ''\n",
    "for i in indices[0]:\n",
    "    data = {\n",
    "        'video_id': frames[i]['video_id'],\n",
    "        'subtitle_start_time': frames[i]['subtitle_start_time'],\n",
    "        'subtitle_end_time': frames[i]['subtitle_end_time'],\n",
    "        'subtitle_text': frames[i]['subtitle_text']\n",
    "    }\n",
    "    yaml_str = yaml.dump(data, default_flow_style=False, allow_unicode=True)\n",
    "    context += yaml_str + '\\n'\n",
    "prompt = prompt.replace('{context}', context).replace('{question}', question)\n",
    "print(\"Prompt:\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8457d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer： Based on the subtitle snippets provided, the theme of the lesson appears to be related to **computer vision** and **convolutional neural networks (CNNs)**. The context mentions a \"discussion about convolutional new\" and \"problems that we are facing in computer vision,\" which suggests that the lesson is focused on addressing challenges in computer vision using convolutional neural networks or similar techniques. However, the exact details of the theme are not fully clarified due to incomplete subtitles. \n",
      "\n",
      "If more context were available, it might confirm whether the lesson is specifically about the fundamentals of CNNs, their applications in computer vision, or methods for solving specific problems in this field.\n"
     ]
    }
   ],
   "source": [
    "def chat(message):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=config.llm_model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message\n",
    "            }\n",
    "        ],\n",
    "        stream=True,\n",
    "        stream_options={\"include_usage\": True}\n",
    "    )\n",
    "    s = ''\n",
    "    for chunk in completion:\n",
    "        if len(chunk.choices)>0:\n",
    "            s += chunk.choices[0].delta.content\n",
    "    return s\n",
    "ans = chat(prompt)\n",
    "print(\"Answer：\", ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
